# -*- coding: utf-8 -*-
"""2nd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14qVWoBM3rBlUQDH3js6tlLaZrN1zPCgv
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

data = {
    'Socio-Economic Status': [1, 3, 2, 1, 3, 2, 3, 1, 2],
    'Age': [30, 45, 22, 35, 50, 28, 32, 29, 40],
    'Gender': ['M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M'],
    'Survived': [1, 1, 1, 0, 0, 1, 1, 0, 1]
}

df = pd.DataFrame(data)

data

df = pd.get_dummies(df, columns=['Gender'], drop_first=True)

df

X = df.drop('Survived', axis=1)
y = df['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy:", accuracy)

feature_importance = model.coef_[0]
for feature, importance in zip(X.columns, feature_importance):
    print(f"{feature}: {importance}")
